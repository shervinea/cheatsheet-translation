**1. Machine Learning tips and tricks cheatsheet**

&#10230; मशीन लर्निंग टिप्स और ट्रिक्स चीट शीट

<br>

**2. Classification metrics**

&#10230; वर्गीकरण मेट्रिक्स (मार्गिक) 

<br>

**3. In a context of a binary classification, here are the main metrics that are important to track in order to assess the performance of the model.**

&#10230; बाइनरी (द्विआधारी) वर्गीकरण मॉडल (निदर्श) के प्रदर्शन का आकलन करने के लिए निम्नलिखित मेट्रिक्स महत्वपूर्ण है।

<br> 

**4. Confusion matrix ― The confusion matrix is used to have a more complete picture when assessing the performance of a model. It is defined as follows:**

&#10230;

<br> कन्फ़्यूज़न (असमंजस) मेट्रिक्स - कन्फ़्यूज़न मेट्रिक्स का उपयोग मॉडल का बेहतेर आकलन के लिए किया जाता है। इसे निम्नानुसार परिभाषित किया गया है।

**5. [Predicted class, Actual class]**

&#10230; [अनुमानित वर्ग, यथार्थ (वास्तविक) वर्ग]

<br>

**6. Main metrics ― The following metrics are commonly used to assess the performance of classification models:**

&#10230;मुख्य मेट्रिक्स - निम्नलिखित मेट्रिक्स का उपयोग वर्गीकरण मॉडल के प्रदर्शन का आकलन करने के लिए होता है।

<br> 

**7. [Metric, Formula, Interpretation]**

&#10230;[मेट्रिक, फ़ॉर्म्युला (सूत्र), व्याख्या ]

<br>

**8. Overall performance of model**

&#10230; मॉडल का समग्र प्रदर्शन

<br> 

**9. How accurate the positive predictions are**

&#10230; सकारात्मक अनुमान कितनी सटीक है 

<br> 

**10. Coverage of actual positive sample**

&#10230;

<br> वास्तविक सकारात्मक नमूनों की व्याप्ति

**11. Coverage of actual negative sample**

&#10230;वास्तविक नकारात्मक नमूनों की व्याप्ति

<br> 

**12. Hybrid metric useful for unbalanced classes**

&#10230;असंतुलित वर्गों के लिए उपयोगी संकर मेट्रिक 

<br> 

**13. ROC ― The receiver operating curve, also noted ROC, is the plot of TPR versus FPR by varying the threshold. These metrics are are summed up in the table below:**

&#10230; आरओसी - रिसीवर ऑपरेटिंग कर्व्ह (वक्र), यानी आरओसी, थ्रेशोल्ड (दहलीज़) बदलकर टीपीआर बनाम एफपीआर का आलेखन है

<br>

**14. [Metric, Formula, Equivalent]**

&#10230;[मेट्रिक, सूत्र, समकक्ष]

<br>

**15. AUC ― The area under the receiving operating curve, also noted AUC or AUROC, is the area below the ROC as shown in the following figure:**

&#10230;AUC - रिसीवर ऑपरेटिंग कर्व्ह के अंदर का क्षेत्र है, जैसा की निम्नलिखित चित्र में दिखाया गया है। इसे एयूसी अथवा एयूआरओसी से भी जाना जाता है। 

<br>

**16. [Actual, Predicted]**

&#10230;[वास्तविक, अनुमानित]

<br>

**17. Basic metrics ― Given a regression model f, the following metrics are commonly used to assess the performance of the model:**

&#10230;मूल मेट्रिक्स - प्रतिगमन मॉडल f में, निम्नलिखित मेट्रिक्स का उपयोग मॉडल के प्रदर्शन का आकलन करने के लिए सामान्यतः किया जाता है।  

<br>

**18. [Total sum of squares, Explained sum of squares, Residual sum of squares]**

&#10230;[वर्गों का कुल योग, वर्गों का प्रतिपादित योग, वर्गों का अवशिष्ट योग,]

<br>

**19. Coefficient of determination ― The coefficient of determination, often noted R2 or r2, provides a measure of how well the observed outcomes are replicated by the model and is defined as follows:**

&#10230;

<br>निर्धारण का गुणांक - निर्धारण का गुणांक को R2 या r2 से भी जाना जाता है। यह मॉडल द्वारा दिखाए गए परिणामों को कितनी अच्छी तरह से दोहराया जाता है इसका एक माप प्रदान करता है। इसे निम्नानुसार परिभाषित किया गया है,

**20. Main metrics ― The following metrics are commonly used to assess the performance of regression models, by taking into account the number of variables n that they take into consideration:**

&#10230; मुख्य मेट्रिक्स - निम्न मेट्रिक्स का उपयोग आमतौर पर प्रतिगमन मॉडल के प्रदर्शन का आकलन करने के लिए किया जाता है। जिसमें प्रतिगमन मॉडल द्वारा आकलन में प्रयुक्त चरो की संख्या को ध्यान में रख कर मेट्रिक्स का आकलन किया जाता है।

<br>

**21. where L is the likelihood and ˆσ2 is an estimate of the variance associated with each response.**

&#10230;२१, जिसमें L सम्भावना तथा ˆσ2 प्रत्येक प्रतिक्रिया से जुड़ी प्रसरण का अनुमान है।

<br>

**22. Model selection**

&#10230; मॉडल (निदर्श) चयन 

<br>

**23. Vocabulary ― When selecting a model, we distinguish 3 different parts of the data that we have as follows:**

&#10230;शब्दावली - निम्न प्रकार से मॉडल का चयन करते समय, आँकड़ो को ३ प्रकार से बाँटा जाता है।

<br> 

**24. [Training set, Validation set, Testing set]**

&#10230;[प्रशिक्षण समुच्चय, पुष्टि समुच्चय, परीक्षण समुच्चय]

<br>

**25. [Model is trained, Model is assessed, Model gives predictions]**

&#10230;[मॉडल को प्रशिक्षित किया जाता है, मॉडल को आँका जाता है, मॉडल अनुमान देता है ]

<br>

**26. [Usually 80% of the dataset, Usually 20% of the dataset]**

&#10230;[सामान्यतः आंकड़ा समुच्चय का ८०%, सामान्यतः आंकड़ा समुच्चय का २०%, ]]

<br>

**27. [Also called hold-out or development set, Unseen data]**

&#10230;[जिसे होल्ड-आउट (प्रतिरोध) या विकसन समुच्चय भी कहा जाता है, अदृष्ट आँकड़े]

<br>

**28. Once the model has been chosen, it is trained on the entire dataset and tested on the unseen test set. These are represented in the figure below:**

&#10230;मॉडल का चुनाव करने के बाद, इसे सम्पूर्ण आंकड़ा समुच्चय पर प्रशिक्षित किया जाता है और अदृष्ट, परीक्षण समुच्चय पर परीक्षित किया जाता है। इसे नीचे दिए चित्र में दर्शाया गया है।

<br>

**29. Cross-validation ― Cross-validation, also noted CV, is a method that is used to select a model that does not rely too much on the initial training set. The different types are summed up in the table below:**

&#10230;परिणाम का सत्यापन - परिणाम का सत्यापन जिसे CV से भी जाना जाता है। इस विधि का उपयोग उस मॉडल का चयन करने का उपयोग किया जाता है जो प्रारम्भिक प्रशिक्षण समुच्चय पर ज़्यादा निर्भर नहीं करता। नीचे दी गई तालिका में विभिन्न प्रकारों का सारांश दिया गया है:

<br>

**30. [Training on k−1 folds and assessment on the remaining one, Training on n−p observations and assessment on the p remaining ones]**

&#10230;[k-१ मोड़ पर प्रशिक्षण एवं शेष पर आंकलन, n-p अवलोकन पर प्रशिक्षण एवं शेष p पर आंकलन]

<br>

**31. [Generally k=5 or 10, Case p=1 is called leave-one-out]**

&#10230;[सामान्यतः k=5 या 10, p=1 को एक को छोड़ दो] 

<br>

**32. The most commonly used method is called k-fold cross-validation and splits the training data into k folds to validate the model on one fold while training the model on the k−1 other folds, all of this k times. The error is then averaged over the k folds and is named cross-validation error.**

&#10230;k-मोड़ परिणाम का सत्यापन एक प्रचलित विधि है। इसमें आँकड़ो को पहले k मोड़ में बाँटा जाता है। फिर 
प्रशिक्षण समुच्चय को k-१ पर प्रशिक्षित किया जाता है, और शेष १ मोड़ परीक्षण समुच्चय उर प्रशिक्षित किया जाता है। इसे k बार दोहराया जाता है। त्रुटि की k मोड़ पर औसत होती है और इसे क्रॉस-सत्यापन त्रुटि कहा जाता है।

<br>

**33. Regularization ― The regularization procedure aims at avoiding the model to overfit the data and thus deals with high variance issues. The following table sums up the different types of commonly used regularization techniques:**

&#10230;नियमन - नियमन प्रक्रिया का उद्देश्य मॉडल को अधिक लायक बनाने से रोकना है और यह अधिक प्रसरण के मुद्दों को देखता है। निम्न तालिका सामान्य रूप से उपयोग की जाने वाली नियमित तकनीकों के विभिन्न प्रकारों को बताती है।

<br>

**34. [Shrinks coefficients to 0, Good for variable selection, Makes coefficients smaller, Tradeoff between variable selection and small coefficients]**

&#10230;[गुनांक को ० तक छोटा करना, चर चयन के लिए अच्छा है, गुणांक छोटे बनाता है, चर चयन और छोटे गुणांक के बीच की दुविधा]]

<br>

**35. Diagnostics**

&#10230;निदान

<br>

**36. Bias ― The bias of a model is the difference between the expected prediction and the correct model that we try to predict for given data points.**

&#10230; पूर्वाग्रह - मॉडल का पूर्वाग्रह, अपेक्षित अनुमान और मॉडल के सही अनुमान के बीच का अंतर।

<br>

**37. Variance ― The variance of a model is the variability of the model prediction for given data points.**

&#10230; प्रसरण (वेरीयन्स)- मॉडल का प्रसरण, चयनित आँकड़ो बिंदुओं के लिए, मॉडल के अनुमान की परिवर्तनशीलता है।

<br>

**38. Bias/variance tradeoff ― The simpler the model, the higher the bias, and the more complex the model, the higher the variance.**

&#10230;पूर्वाग्रह/प्रसरण की दुविधा - मॉडल जितना सरल उतना ज़्यादा पूर्वाग्रह। मॉडल जितना कठिन उतना ज़्यादा प्रसरण। 

<br>

**39. [Symptoms, Regression illustration, classification illustration, deep learning illustration, possible remedies]**

&#10230;[लक्षण, प्रतिगमन चित्रण, वर्गीकरण चित्रण, डीप लर्निंग का चित्रण, संभावित उपचार ]

<br>

**40. [High training error, Training error close to test error, High bias, Training error slightly lower than test error, Very low training error, Training error much lower than test error, High variance]**

&#10230;[उच्च प्रशिक्षण त्रुटि, परीक्षण त्रुटि के करीब प्रशिक्षण त्रुटि, उच्च पूर्वाग्रह, परीक्षण त्रुटि से थोड़ी कम प्रशिक्षण त्रुटि, बहुत कम प्रशिक्षण त्रुटि, परीक्षण त्रुटि से बहुत कम प्रशिक्षण त्रुटि, उच्च प्रसरण]

<br>

**41. [Complexify model, Add more features, Train longer, Perform regularization, Get more data]**

&#10230;[मॉडल को जटिल बनाएं, और विशेषताएं जोड़ें,  अधिक प्रशिक्षण दे, नियमितकरण करें, अधिक आँकड़े प्राप्त करें]

<br>

**42. Error analysis ― Error analysis is analyzing the root cause of the difference in performance between the current and the perfect models.**

&#10230;त्रुटि विश्लेषण - मौजूद मॉडल और दोषहीन मॉडल के बीच प्रदर्शन में अंतर के मूल कारण का विश्लेषण को त्रुटि विश्लेषण कहा जाता है।

<br>

**43. Ablative analysis ― Ablative analysis is analyzing the root cause of the difference in performance between the current and the baseline models.**

&#10230;विभक्ति (ऐब्लटिव) विश्लेषण - विभक्ति विश्लेषण वर्तमान और बुनियादी मॉडल के बीच प्रदर्शन में अंतर का मूल कारण विश्लेषण कर रहा है

<br>

**44. Regression metrics**

&#10230;प्रतिगमन मेट्रिक्स 

<br>

**45. [Classification metrics, confusion matrix, accuracy, precision, recall, F1 score, ROC]**

&#10230;[वर्गीकरण मीट्रिक, असमंजस मैट्रिक्स, सटीकता, परिशुद्धता, याद, एफ 1 स्कोर, आरओसी]

<br>

**46. [Regression metrics, R squared, Mallow's CP, AIC, BIC]**

&#10230;[प्रतिगमन मेट्रिक्स, आर स्क्वेर्ड, मैलो की सीपी, एआईसी, बीआईसी]

<br>

**47. [Model selection, cross-validation, regularization]**

&#10230;[मॉडल का चयन, परिणाम का सत्यापन, नियमन]

<br>

**48. [Diagnostics, Bias/variance tradeoff, error/ablative analysis]**

&#10230;[निदान, पूर्वाग्रह/प्रसरण की दुविधा, त्रुटि/विभक्ती विश्लेषण]
